Imagine you manufacture airplane engines
Measure engines as they come off the line
    x1 = heat generated
    x2 = vibration intensity
    etc
This gives us a dataset x1, x2, ..., xm
We need to know whether a newly manufactured engine needs further testing

We usually assume that our training data contains no anomalies
Create model p(x)
If p(xtest) < ε, flag as anomaly
If p(xtest) ≥ ε, treat as good

This technique can be used for:
    fraud detection (user behavior)
        Really identifies unusual behavior, not necessarily fraud
    manufacturing
    monitoring computers in a data center

Gaussian Distribution (Normal distribution)
For a variable x which has a Gaussian distribution with mean μ and variance σ² we write
    x ~ N(μ, σ²)
PDF = 1/sqrt(2Π)σ * exp(-(x-μ)²/2σ²)
Parameter estimation problem:
    Let's say we suspect each of our examples, xi has a Gaussian distribution with some unknown
        μ and σ
    Estimate μ = the average of our xi values = 1/m * Σxi
        σ² = 1/m Σ(xi - μ)²
        Note that the m in the denominator of σ² is usually m-1 in mathematics
            For ML, with reasonably large values of m, this makes no difference

Algorithm:
Training set = x1, ..., xm
xi has n features
p(x) = p(x1; μ1, σ1²)*p(x2; μ2, σ2²)*...*p(xm; μm, σm²)
    Note that this looks like the probability for m independent variables, each of Gaussian distribution
    It turns out that this algorithm will work REGARDLESS of the independence
p(x) = Π(xj; υj, σj²)

1.  Choose features xi that might indicate an anomaly
2.  Fit parameters μj and σj² for j = 1:n (one parameter set per feature)
        μj = 1/m * Σxj(i) (sum over i = 1 to m)
            The vectorized version would be μ = 1/m * Σxi
        σ² = 1/m * Σ(xj(i) - μj) (sum over i = 1 to m)
3.  Given a new example x, compute:
        p(x) = Π(xj; υj, σj²) = Π 1/sqrt(2π)σj * exp(-(xj-μj)²/2σj²) (multiply over j = 1 to n)
4.  Predict anomaly if p(x) < ε

Develop and evaluate an anomaly detection system
As before, we want real number evaluation to allow us to see at a glance whether adding or removing
    a feature improves our model or not
Assume we have some labeled data, of anomalous and regular examples
    y = 0 →  normal
    y = 1 →  anomalous
Our training set is x1, ..., xm of regular examples only (no anomalies)
    (It's actually ok if some anomalies slip in)
Create cross validation and test sets

Let's say we have a data set of 10,000 regular engines
20 flawed engines

Create a training set of 6000 regular engines
CV: 2000 regular, 10 anomalous
Test: 2000 regular, 10 anomalous

Fit the model p(x) on training set
On CV and test, predict y = 1 or 0 depending on whether p(x) < ε or not
Evaluate the algorithm
    What metric should we use?
    The skewed data (rare anomalies) means that classification accuracy is a bad idea
    As before, we can use the following:
        True pos, false pos, false neg, true neg values and ratios
        Precision/Recall
        F1 score
We can use the CV set to adjust ε
    Try many values and find the one that maximizes your metric of choice

So, if we use labelled data to train an anomaly detection system, how does this differ from 
    supervised learning? When should we choose one over the other?
Very small number of positive (anomalous) examples (0-20) - AD lets us save them for CV/Test sets
Large number of negative examples: AD lets us have a large training set without the need for negative
    examples
Many different types of anomalies: hard for any algorithm to learn from the positive examples
In a similar vein, future anomalies may not resemble any we have seen so far
Basically, AD excels at learning from just the negative examples

If we have a large number of negative and positive examples, Supervised learning is a good choice

Having decided on AD, how do we select features for it?
    Plot data to ensure it's more or less Gaussian
    Can use hist function in Octave to plot each feature
    Even if the data is not Gaussian, AD may work all right
        However, we can do things like take the log of a feature to see if we can make it Gaussian
        A log transformation is generally log(xi + ci) where ci is a constant
        May also use fractional exponents x^1/3, etc

    We want p(x) large for regular examples and small for anomalous examples
    A common problem is when we have similar p(x) values for both types of examples
    Find a problematic example and see if any of its features have unusual values

In general we want to find features that have unusual values for anomalies
Say we are monitoring computers in a data center
    x1 = memory use
    x2 = disk accesses / sec
    x3 = CPU load
    x4 = network traffic

Normally, we expect that CPU load and network traffic tend to grow linearly together.
If I suspect that one failure case may be a process stuck in an infinite loop,
    I might look for cases where the CPU load outpaces the network traffic as it spins its wheels
    x5 = CPU load / network traffic
    Now I can look for large values of x5

Multivariate Gaussian Distribution:
x ∈  Rⁿ
Don't model p(x1), p(x2), etc separately
Instead model p(x) all in one go
parameters: μ ∈  Rⁿ, Σ ∈  R(nxn) (covariance matrix)
Default value for Σ = 1/m * Σ(xi - μ)(xi - μ)'
    μ = 1/m * Σxi
Then p(x; μ, Σ) = 1/((2π)^(n/2) * |Σ|^(1/2)) * exp(-1/2 * (x-μ)' * Σinv * (x-μ))
    |Σ| is the determinant of sigma
    Can use det(sigma) in Octave
How do we use this to detect anomalies?
    Fit the model using the default values for μ and Σ
    Given a new example compute p(x) using the formula above
Note: our original model corresponds to the multivariate case where Σ is a diagonal matrix
One advantage of this approach is that it captures correlations between features
    This means we don't have to manually capture relationships between features
The original model is computationally cheaper and scales better.
    Works for values of n in the 100k range
The original model works better with small data sets
    Multivariate model requires m > n, else Σ is singular which fouls up our equations which rely on
    its inverse
    In practice we want m >> n for multivariate (on the order of m > 10n)
Σ may also be singular if we have linearly dependent features (x1 = x2 or x3 = x4 + x5)
    These are indicative of bad features anyways
If we find a singular Σ:
    Check m > n
    Check for redundant features

    
